{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "English_Sentiment_Analysis_Submission",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6ee37a04362143f783c5d0309407052e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fc3192e45a3941d092674c27db975121",
              "IPY_MODEL_5db3b31b6eff42a783106cb43b156287"
            ],
            "layout": "IPY_MODEL_3e4e5ebee6f0451981f0892d244b0a7e"
          }
        },
        "fc3192e45a3941d092674c27db975121": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f844a6efac1a4ba6b2a014290fb68871",
            "max": 299,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9b0539d7d26845049457a9b64c9243ff",
            "value": 299
          }
        },
        "5db3b31b6eff42a783106cb43b156287": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b527e6f12154b978085348928e7708d",
            "placeholder": "​",
            "style": "IPY_MODEL_dcf62b4c3dfe4d969c81d969395ab6b5",
            "value": " 299/299 [07:32&lt;00:00,  1.51s/it]"
          }
        },
        "3e4e5ebee6f0451981f0892d244b0a7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f844a6efac1a4ba6b2a014290fb68871": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b0539d7d26845049457a9b64c9243ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "7b527e6f12154b978085348928e7708d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcf62b4c3dfe4d969c81d969395ab6b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b96fe839ba540c680e5dbd9fec649e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fc41e7486eb0496a8ef4d5b6326f8dca",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5613e50d00f64fd08b9bc91f564a2633",
              "IPY_MODEL_6d8a89285c584bfd8aa32e1491676551"
            ]
          }
        },
        "fc41e7486eb0496a8ef4d5b6326f8dca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5613e50d00f64fd08b9bc91f564a2633": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f81917b3f5a040579d17f712e776f4cd",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1623,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1623,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2b05d1d3409b4616af1352475228a69e"
          }
        },
        "6d8a89285c584bfd8aa32e1491676551": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_04d29e8655dd4d30bcaf24c55b1e173d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1623/1623 [38:36&lt;00:00,  1.43s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c70b713583e14f87a5edd4b6b1808d3f"
          }
        },
        "f81917b3f5a040579d17f712e776f4cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2b05d1d3409b4616af1352475228a69e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "04d29e8655dd4d30bcaf24c55b1e173d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c70b713583e14f87a5edd4b6b1808d3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nawon0719/KU-NLP-Sentiment-Analysis/blob/main/English_Sentiment_Analysis_Submission.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-R3lgoiLGLR0"
      },
      "source": [
        "#준비사항"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6L4cQQhK5Ct0",
        "outputId": "7d149a2a-c5e4-44f8-9b94-7aff148697fd"
      },
      "source": [
        "!pip install transformers\r\n",
        "!pip install torch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.7.0+cu101)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch) (0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.19.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgHf7SD7uFuK"
      },
      "source": [
        "분석 환경 셋팅"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruNN11LG5X4u"
      },
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "\n",
        "import transformers\n",
        "from transformers import ElectraTokenizer, ElectraModel, ElectraConfig, ElectraForSequenceClassification\n",
        "from transformers import AdamW , get_linear_schedule_with_warmup\n",
        "from transformers.modeling_tf_utils import get_initializer,keras_serializable, shape_list\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from google.colab import files\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import datetime\n",
        "import json\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-0roV-569a3"
      },
      "source": [
        "#제이슨 타입 파일 처리용\n",
        "def jsonToDf(file_name):\n",
        "  with open(file_name, encoding = 'CP1252', mode = 'r') as file:\n",
        "    json_array = json.load(file)\n",
        "  \n",
        "  result = pd.DataFrame.from_dict(json_array[0])\n",
        "\n",
        "  is_first = True\n",
        "  for array in json_array:\n",
        "    if is_first:\n",
        "      is_first = False\n",
        "      continue\n",
        "    \n",
        "    temp_df = pd.DataFrame.from_dict(array)\n",
        "    result = result.append(temp_df, ignore_index = True)\n",
        "\n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PNVfnDtvlIq"
      },
      "source": [
        "#Train set 로드\r\n",
        "EmotionX push, train 데이터 추가 적용"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRIlUhu08hSF"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Q6egFjJ48qzG",
        "outputId": "c97320d9-1ce6-46d4-e629-35eafd9bd685"
      },
      "source": [
        "train = jsonToDf('friends_train.json')\n",
        "dev = jsonToDf('friends_dev.json')\n",
        "train2=jsonToDf('emotionpush.json')\n",
        "train3=jsonToDf('emotionpush.train.json')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>speaker</th>\n",
              "      <th>utterance</th>\n",
              "      <th>emotion</th>\n",
              "      <th>annotation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Phoebe</td>\n",
              "      <td>Oh my God, hes lost it. Hes totally lost it.</td>\n",
              "      <td>non-neutral</td>\n",
              "      <td>0002120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Monica</td>\n",
              "      <td>What?</td>\n",
              "      <td>surprise</td>\n",
              "      <td>1000130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ross</td>\n",
              "      <td>Or! Or, we could go to the bank, close our acc...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Chandler</td>\n",
              "      <td>Youre a genius!</td>\n",
              "      <td>joy</td>\n",
              "      <td>0500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Joey</td>\n",
              "      <td>Aww, man, now we wont be bank buddies!</td>\n",
              "      <td>sadness</td>\n",
              "      <td>0040100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    speaker  ... annotation\n",
              "0    Phoebe  ...    0002120\n",
              "1    Monica  ...    1000130\n",
              "2      Ross  ...    3000200\n",
              "3  Chandler  ...    0500000\n",
              "4      Joey  ...    0040100\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmliMLzI85i6",
        "outputId": "46465720-e663-4b22-e063-b7322901c65c"
      },
      "source": [
        "print(train.shape)\n",
        "print(dev.shape)\n",
        "print(train2.shape)\n",
        "print(train3.shape)\n",
        "print(train2['emotion'].value_counts())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10561, 4)\n",
            "(1178, 4)\n",
            "(14742, 4)\n",
            "(10733, 4)\n",
            "neutral        9855\n",
            "joy            2100\n",
            "non-neutral    1418\n",
            "surprise        567\n",
            "sadness         514\n",
            "anger           140\n",
            "disgust         106\n",
            "fear             42\n",
            "Name: emotion, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "HjHjn-buDZu4",
        "outputId": "4aab408a-f1f9-46c3-ebcf-3bc1bac797d2"
      },
      "source": [
        "#train, dev, train2, train3 데이터 합쳐서 새로운 트레인 데이터셋 구축\r\n",
        "new_train=pd.concat([train, dev, train2, train3],ignore_index=True)\r\n",
        "new_train=new_train.drop(columns=['speaker','annotation'])\r\n",
        "new_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>utterance</th>\n",
              "      <th>emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>also I was the point person on my companys tr...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>You mustve had your hands full.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>That I did. That I did.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>So lets talk a little bit about your duties.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>My duties?  All right.</td>\n",
              "      <td>surprise</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37209</th>\n",
              "      <td>It's Young Money</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37210</th>\n",
              "      <td>Oh I was looking down near the 73s</td>\n",
              "      <td>surprise</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37211</th>\n",
              "      <td>You're at 86</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37212</th>\n",
              "      <td>Yea but idk if the 15% you get off for handing...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37213</th>\n",
              "      <td>I don't think it does</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>37214 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               utterance   emotion\n",
              "0      also I was the point person on my companys tr...   neutral\n",
              "1                       You mustve had your hands full.   neutral\n",
              "2                                That I did. That I did.   neutral\n",
              "3          So lets talk a little bit about your duties.   neutral\n",
              "4                                 My duties?  All right.  surprise\n",
              "...                                                  ...       ...\n",
              "37209                                   It's Young Money   neutral\n",
              "37210                 Oh I was looking down near the 73s  surprise\n",
              "37211                                       You're at 86   neutral\n",
              "37212  Yea but idk if the 15% you get off for handing...   neutral\n",
              "37213                              I don't think it does   neutral\n",
              "\n",
              "[37214 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGdjOpb0dexh",
        "outputId": "a62f2828-c65f-447a-8976-4c91ed7709e9"
      },
      "source": [
        "new_train['emotion'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "neutral        22246\n",
              "joy             4988\n",
              "non-neutral     4713\n",
              "surprise        2373\n",
              "sadness         1316\n",
              "anger            832\n",
              "disgust          454\n",
              "fear             292\n",
              "Name: emotion, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ppfQ7A-FiQS"
      },
      "source": [
        "#전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWZWmnQon2rF"
      },
      "source": [
        "##Spell Checker"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1-Oy-Qj8vqu"
      },
      "source": [
        "실시간으로 spell checker실행하지 않고 교정완료 된 버전의 파일 불러와서 사용 가능"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38KVBnWFn6g7",
        "outputId": "a2d96133-fb97-4780-ac43-55e09de132da"
      },
      "source": [
        "!pip install tqdm\r\n",
        "!pip install language-tool-python==2.4.7"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: contextualSpellCheck==0.3.3 in /usr/local/lib/python3.6/dist-packages (0.3.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from contextualSpellCheck==0.3.3) (1.7.0+cu101)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (from contextualSpellCheck==0.3.3) (4.1.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (from contextualSpellCheck==0.3.3) (2.2.4)\n",
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.6/dist-packages (from contextualSpellCheck==0.3.3) (0.5.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->contextualSpellCheck==0.3.3) (1.19.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->contextualSpellCheck==0.3.3) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->contextualSpellCheck==0.3.3) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch->contextualSpellCheck==0.3.3) (0.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers->contextualSpellCheck==0.3.3) (20.8)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers->contextualSpellCheck==0.3.3) (0.0.43)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers->contextualSpellCheck==0.3.3) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers->contextualSpellCheck==0.3.3) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers->contextualSpellCheck==0.3.3) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers->contextualSpellCheck==0.3.3) (3.0.12)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers->contextualSpellCheck==0.3.3) (0.9.4)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->contextualSpellCheck==0.3.3) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->contextualSpellCheck==0.3.3) (2.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->contextualSpellCheck==0.3.3) (3.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->contextualSpellCheck==0.3.3) (7.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->contextualSpellCheck==0.3.3) (1.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy->contextualSpellCheck==0.3.3) (51.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->contextualSpellCheck==0.3.3) (1.1.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->contextualSpellCheck==0.3.3) (0.8.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->contextualSpellCheck==0.3.3) (0.4.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy->contextualSpellCheck==0.3.3) (1.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers->contextualSpellCheck==0.3.3) (2.4.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers->contextualSpellCheck==0.3.3) (1.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers->contextualSpellCheck==0.3.3) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers->contextualSpellCheck==0.3.3) (7.1.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers->contextualSpellCheck==0.3.3) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers->contextualSpellCheck==0.3.3) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers->contextualSpellCheck==0.3.3) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers->contextualSpellCheck==0.3.3) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->contextualSpellCheck==0.3.3) (3.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->contextualSpellCheck==0.3.3) (3.4.0)\n",
            "Requirement already satisfied: pyspellchecker in /usr/local/lib/python3.6/dist-packages (0.5.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.41.1)\n",
            "Collecting language-tool-python==2.4.7\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/b0/2a67ec6a7ff914edbb3b2ba335a711ca3a564ad4189ed16d33b67e3b0426/language_tool_python-2.4.7-py3-none-any.whl\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from language-tool-python==2.4.7) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from language-tool-python==2.4.7) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->language-tool-python==2.4.7) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->language-tool-python==2.4.7) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->language-tool-python==2.4.7) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->language-tool-python==2.4.7) (2020.12.5)\n",
            "Installing collected packages: language-tool-python\n",
            "Successfully installed language-tool-python-2.4.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_M5tsSjQKmV"
      },
      "source": [
        "import language_tool_python\r\n",
        "tool = language_tool_python.LanguageTool('en-US') \r\n",
        "from tqdm.notebook import tqdm "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "6ee37a04362143f783c5d0309407052e",
            "fc3192e45a3941d092674c27db975121",
            "5db3b31b6eff42a783106cb43b156287",
            "3e4e5ebee6f0451981f0892d244b0a7e",
            "f844a6efac1a4ba6b2a014290fb68871",
            "9b0539d7d26845049457a9b64c9243ff",
            "7b527e6f12154b978085348928e7708d",
            "dcf62b4c3dfe4d969c81d969395ab6b5"
          ]
        },
        "id": "oAxAISazGWXs",
        "outputId": "1e01cf4e-dd65-47a3-86ab-a0f0b38038ff"
      },
      "source": [
        "#Train 데이터 spell check\r\n",
        "for i in tqdm(range(len(new_train))):\r\n",
        "  try:\r\n",
        "    test_data['utterance'][i] = tool.correct(test_data['utterance'][i])\r\n",
        "  except:\r\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6ee37a04362143f783c5d0309407052e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=299.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "hVQZfmSEuhcp",
        "outputId": "d397bf10-5804-42d1-801b-2eed02dfd5e2"
      },
      "source": [
        "#데이터손실 방지 위해 csv저장\r\n",
        "test_spell=new_train.to_csv('friends_train_spell_done.csv',encoding='utf-8', index=False)\r\n",
        "from google.colab import files\r\n",
        "\r\n",
        "files.download('friends_train_spell_done3.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_3884e89b-4cef-4379-ad6c-563f1e9b27f2\", \"friends_train_spell_done3.csv\", 1571539)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "q2wceqcke1A0",
        "outputId": "d8a51646-158f-4dda-cb65-9044f0975b4b"
      },
      "source": [
        "#검사완료한 버전 읽어오기\r\n",
        "new_train = pd.read_csv(\"/content/friends_train_spell_done.csv\", encoding='utf-8', sep=',')\r\n",
        "new_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>utterance</th>\n",
              "      <th>emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Also I was the point person on my company tran...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>You must had your hands full.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>That I did. That I did.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>So lets talk a little about your duties.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>My duties?  All right.</td>\n",
              "      <td>surprise</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37209</th>\n",
              "      <td>It's Young Money</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37210</th>\n",
              "      <td>Oh, I was looking down near the 73s</td>\n",
              "      <td>surprise</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37211</th>\n",
              "      <td>You're at 86</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37212</th>\n",
              "      <td>Yea but IDK if the 15% you get off for handing...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37213</th>\n",
              "      <td>I don't think it does</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>37214 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               utterance   emotion\n",
              "0      Also I was the point person on my company tran...   neutral\n",
              "1                          You must had your hands full.   neutral\n",
              "2                                That I did. That I did.   neutral\n",
              "3               So lets talk a little about your duties.   neutral\n",
              "4                                 My duties?  All right.  surprise\n",
              "...                                                  ...       ...\n",
              "37209                                   It's Young Money   neutral\n",
              "37210                Oh, I was looking down near the 73s  surprise\n",
              "37211                                       You're at 86   neutral\n",
              "37212  Yea but IDK if the 15% you get off for handing...   neutral\n",
              "37213                              I don't think it does   neutral\n",
              "\n",
              "[37214 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YE6nNr85MCI4"
      },
      "source": [
        "##Train/Validation set 구분"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "konH9F5kUJak"
      },
      "source": [
        "new_train, new_val =train_test_split(new_train, test_size=0.2, random_state=2020, shuffle='TRUE')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ywuYpACL0Ja",
        "outputId": "8ba632d4-4118-4450-8af2-eba1913ece83"
      },
      "source": [
        "print(new_train['emotion'].value_counts())\r\n",
        "print(new_val['emotion'].value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "neutral        17726\n",
            "joy             4035\n",
            "non-neutral     3780\n",
            "surprise        1927\n",
            "sadness         1034\n",
            "anger            660\n",
            "disgust          375\n",
            "fear             234\n",
            "Name: emotion, dtype: int64\n",
            "neutral        4520\n",
            "joy             953\n",
            "non-neutral     933\n",
            "surprise        446\n",
            "sadness         282\n",
            "anger           172\n",
            "disgust          79\n",
            "fear             58\n",
            "Name: emotion, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVqWSnsjXSUP"
      },
      "source": [
        "##불균형 데이터 조절\r\n",
        "train data만 단순 반복을 통한 오버샘플링\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NO8GMv1uP7NY"
      },
      "source": [
        "f=new_train[new_train['emotion']=='fear']\r\n",
        "d=new_train[new_train['emotion']=='disgust']\r\n",
        "a=new_train[new_train['emotion']=='anger']\r\n",
        "sad=new_train[new_train['emotion']=='sadness']\r\n",
        "sup=new_train[new_train['emotion']=='surprise']\r\n",
        "joy=new_train[new_train['emotion']=='joy']\r\n",
        "non=new_train[new_train['emotion']=='non-neutral']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "6ox-FX7OT3v3",
        "outputId": "aeb4d954-339b-4b78-e6a3-3a7d5151f1e4"
      },
      "source": [
        "new_train=pd.concat([new_train,f,f,f,f,f,f,f],ignore_index=True)\r\n",
        "new_train=pd.concat([new_train,d,d,d,d,d,d,d],ignore_index=True)\r\n",
        "new_train=pd.concat([new_train,a,a,a,a,a],ignore_index=True)\r\n",
        "new_train=pd.concat([new_train,sad,sad,sad,sad],ignore_index=True)\r\n",
        "new_train=pd.concat([new_train,sup,sup,sup,sup,joy,joy,non,non],ignore_index=True)\r\n",
        "\r\n",
        "print(new_train['emotion'].value_counts())\r\n",
        "new_train.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "neutral        17726\n",
            "joy            12105\n",
            "non-neutral    11340\n",
            "surprise        9635\n",
            "sadness         5170\n",
            "anger           3960\n",
            "disgust         3000\n",
            "fear            1872\n",
            "Name: emotion, dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>utterance</th>\n",
              "      <th>emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>64803</th>\n",
              "      <td>Hey! How it goes?</td>\n",
              "      <td>non-neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64804</th>\n",
              "      <td>It actually says that</td>\n",
              "      <td>non-neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64805</th>\n",
              "      <td>See? IBM doing it. I am totally doing it.  I l...</td>\n",
              "      <td>non-neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64806</th>\n",
              "      <td>Noon</td>\n",
              "      <td>non-neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64807</th>\n",
              "      <td>Oh-ho yeah! A song with rhyming words. OO, I n...</td>\n",
              "      <td>non-neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               utterance      emotion\n",
              "64803                                  Hey! How it goes?  non-neutral\n",
              "64804                              It actually says that  non-neutral\n",
              "64805  See? IBM doing it. I am totally doing it.  I l...  non-neutral\n",
              "64806                                               Noon  non-neutral\n",
              "64807  Oh-ho yeah! A song with rhyming words. OO, I n...  non-neutral"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7H7HWUGcMzh",
        "outputId": "934ce3ac-8224-495e-c40d-369def9fe067"
      },
      "source": [
        "len(new_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64808"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4xYvJl_Dosd"
      },
      "source": [
        "##데이터 인풋"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmyUQewC7Hn0"
      },
      "source": [
        "MAX_LEN = 128\n",
        "\n",
        "def getInputsAndLabels(dataset):\n",
        "  data = dataset.copy(deep=True)\n",
        "  \n",
        "  #문장추출\n",
        "  utterances = data['utterance'] #train, val data\n",
        "  utterances = [\"[CLS] \" + str(utterance) + \" [SEP]\" for utterance in utterances]\n",
        "  \n",
        "  #str타입 라벨 처리\n",
        "  encoder = LabelEncoder()\n",
        "  labels = data['emotion'].values\n",
        "  encoder.fit(labels)\n",
        "  labels = encoder.transform(labels)\n",
        "\n",
        "  #ELECTRA Tokenizer\n",
        "  tokenizer = ElectraTokenizer.from_pretrained('google/electra-base-discriminator',do_lower_case=False)\n",
        "  tokenized_texts = [tokenizer.tokenize(utterance) for utterance in utterances]\n",
        "\n",
        "  #토큰을 숫자 인덱스로 변환\n",
        "  input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "  input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "  #어텐션 마스크\n",
        "  attention_masks = []\n",
        "  for seq in input_ids:\n",
        "      seq_mask = [float(i>0) for i in seq]\n",
        "      attention_masks.append(seq_mask)\n",
        "\n",
        "  return input_ids, labels, attention_masks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EVlb_5RnptP"
      },
      "source": [
        "#제출용 테스트에서 인풋가져오기\n",
        "def getInputsFromTest(dataset):\n",
        "  data = dataset.copy(deep=True)\n",
        "\n",
        "  utterances = data['utterance']\n",
        "  utterances = [\"[CLS] \" + str(utterance) + \" [SEP]\" for utterance in utterances]\n",
        "\n",
        "  tokenizer = ElectraTokenizer.from_pretrained('google/electra-base-discriminator', do_lower_case=False)\n",
        "  tokenized_texts = [tokenizer.tokenize(utterance) for utterance in utterances]\n",
        "\n",
        "  input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "  input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "  attention_masks = []\n",
        "  for seq in input_ids:\n",
        "      seq_mask = [float(i>0) for i in seq]\n",
        "      attention_masks.append(seq_mask)\n",
        "\n",
        "  return input_ids, attention_masks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnirJQxrERms"
      },
      "source": [
        "#제출용 테스트데이터 인덱스 \n",
        "def getIndex(dataset):\n",
        "  data = dataset.copy(deep = True)\n",
        "  input_index = data.index.tolist()\n",
        "  return torch.tensor(input_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwNgpRzc7lIv"
      },
      "source": [
        "train_inputs, train_labels, train_masks = getInputsAndLabels(new_train) #새로운 데이터셋\n",
        "val_inputs, val_labels, val_masks = getInputsAndLabels(new_val) # 20% 분리한 검증데이터"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0jKFX9b_RMo"
      },
      "source": [
        "# train, val 데이터 파이토치 텐서로 변환\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "train_masks = torch.tensor(train_masks)\n",
        "\n",
        "validation_inputs = torch.tensor(val_inputs)\n",
        "validation_labels = torch.tensor(val_labels)\n",
        "validation_masks = torch.tensor(val_masks)\t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzhWV0-V0WEq",
        "outputId": "3e37128e-456b-4db0-e1b4-bc09d56cd13a"
      },
      "source": [
        "print(train_inputs[4])\r\n",
        "print(train_masks[4])\r\n",
        "print(train_labels[4])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([  101,   100,  3398,  1010,  3856,  1037,  3124,  1010,  4261, 17134,\n",
            "         2629,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0])\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0.])\n",
            "tensor(4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zl6EOni__5M"
      },
      "source": [
        "batch_size = 32\n",
        "\n",
        "# 파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\n",
        "# 학습시 배치 사이즈 만큼 데이터를 가져옴\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AO2EtdExAmiG"
      },
      "source": [
        "# **모델 생성**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3optSLG6d-d"
      },
      "source": [
        "디바이스 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EN-mJst1Fn7x",
        "outputId": "fe54bbb7-9d95-4ecd-be4e-0cc9d75e8c2f"
      },
      "source": [
        "if torch.cuda.is_available():    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print('No GPU available, using the CPU instead.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla V100-SXM2-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFzjHsAOlilX",
        "outputId": "c00d796a-a5e2-45c8-85dc-d55d6fb43187"
      },
      "source": [
        "# ELECTRA 모델 생성 > bert로도 테스팅\r\n",
        "model = ElectraForSequenceClassification.from_pretrained(\"google/electra-base-discriminator\", num_labels = 8)\r\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at google/electra-base-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias']\n",
            "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-base-discriminator and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ElectraForSequenceClassification(\n",
              "  (electra): ElectraModel(\n",
              "    (embeddings): ElectraEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): ElectraEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): ElectraClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=8, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXcncqM4Ghpl"
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 3e-5,\n",
        "                  eps = 1e-8\n",
        "                )\n",
        "\n",
        "epochs = 10\n",
        "\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ol_8ST0tHTJX"
      },
      "source": [
        "# **학습**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgM7XAN8HVPK"
      },
      "source": [
        "# 정확도 계산 함수\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-THBm2UHZJb"
      },
      "source": [
        "# 시간 표시 함수\n",
        "def format_time(elapsed):\n",
        "\n",
        "    # 반올림\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # hh:mm:ss으로 형태 변경\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Xnc1vL3HcHF",
        "outputId": "bfa5bd5d-2cc3-4b20-d8e2-a7199c511058"
      },
      "source": [
        "seed_val = 1211\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# 그래디언트 초기화\n",
        "model.zero_grad()\n",
        "\n",
        "# 에폭만큼 반복\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "#Training Section\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    t0 = time.time()\n",
        "    total_loss = 0\n",
        "    model.train()\n",
        "        \n",
        "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # 경과 정보 표시\n",
        "        if step % 500 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "                \n",
        "        outputs = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask, \n",
        "                        labels=b_labels)\n",
        "        \n",
        "        loss = outputs[0]\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        # 그래디언트 클리핑\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # 그래디언트를 통해 가중치 파라미터 업데이트\n",
        "        optimizer.step()\n",
        "\n",
        "        # 스케줄러로 학습률 감소\n",
        "        scheduler.step()\n",
        "\n",
        "        # 그래디언트 초기화\n",
        "        model.zero_grad()\n",
        "\n",
        "    # 평균 로스 계산\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.4f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "### Validation Section ### \n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    for batch in validation_dataloader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        with torch.no_grad():     \n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        logits = outputs[0]\n",
        "\n",
        "        # CPU로 데이터 이동\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # 출력 로직과 라벨을 비교하여 정확도 계산\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    print(\"  Accuracy: {0:.5f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 10 ========\n",
            "Training...\n",
            "  Batch   500  of  2,026.    Elapsed: 0:01:58.\n",
            "  Batch 1,000  of  2,026.    Elapsed: 0:03:55.\n",
            "  Batch 1,500  of  2,026.    Elapsed: 0:05:53.\n",
            "  Batch 2,000  of  2,026.    Elapsed: 0:07:51.\n",
            "\n",
            "  Average training loss: 1.2283\n",
            "  Training epcoh took: 0:07:57\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.60276\n",
            "  Validation took: 0:00:15\n",
            "\n",
            "======== Epoch 2 / 10 ========\n",
            "Training...\n",
            "  Batch   500  of  2,026.    Elapsed: 0:01:57.\n",
            "  Batch 1,000  of  2,026.    Elapsed: 0:03:54.\n",
            "  Batch 1,500  of  2,026.    Elapsed: 0:05:51.\n",
            "  Batch 2,000  of  2,026.    Elapsed: 0:07:48.\n",
            "\n",
            "  Average training loss: 0.6029\n",
            "  Training epcoh took: 0:07:54\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.67725\n",
            "  Validation took: 0:00:15\n",
            "\n",
            "======== Epoch 3 / 10 ========\n",
            "Training...\n",
            "  Batch   500  of  2,026.    Elapsed: 0:01:57.\n",
            "  Batch 1,000  of  2,026.    Elapsed: 0:03:54.\n",
            "  Batch 1,500  of  2,026.    Elapsed: 0:05:50.\n",
            "  Batch 2,000  of  2,026.    Elapsed: 0:07:46.\n",
            "\n",
            "  Average training loss: 0.4201\n",
            "  Training epcoh took: 0:07:52\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.67175\n",
            "  Validation took: 0:00:15\n",
            "\n",
            "======== Epoch 4 / 10 ========\n",
            "Training...\n",
            "  Batch   500  of  2,026.    Elapsed: 0:01:57.\n",
            "  Batch 1,000  of  2,026.    Elapsed: 0:03:53.\n",
            "  Batch 1,500  of  2,026.    Elapsed: 0:05:49.\n",
            "  Batch 2,000  of  2,026.    Elapsed: 0:07:45.\n",
            "\n",
            "  Average training loss: 0.3562\n",
            "  Training epcoh took: 0:07:51\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.69754\n",
            "  Validation took: 0:00:15\n",
            "\n",
            "======== Epoch 5 / 10 ========\n",
            "Training...\n",
            "  Batch   500  of  2,026.    Elapsed: 0:01:55.\n",
            "  Batch 1,000  of  2,026.    Elapsed: 0:03:51.\n",
            "  Batch 1,500  of  2,026.    Elapsed: 0:05:46.\n",
            "  Batch 2,000  of  2,026.    Elapsed: 0:07:42.\n",
            "\n",
            "  Average training loss: 0.3217\n",
            "  Training epcoh took: 0:07:48\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.69147\n",
            "  Validation took: 0:00:15\n",
            "\n",
            "======== Epoch 6 / 10 ========\n",
            "Training...\n",
            "  Batch   500  of  2,026.    Elapsed: 0:01:57.\n",
            "  Batch 1,000  of  2,026.    Elapsed: 0:03:54.\n",
            "  Batch 1,500  of  2,026.    Elapsed: 0:05:50.\n",
            "  Batch 2,000  of  2,026.    Elapsed: 0:07:47.\n",
            "\n",
            "  Average training loss: 0.2956\n",
            "  Training epcoh took: 0:07:53\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.70363\n",
            "  Validation took: 0:00:15\n",
            "\n",
            "======== Epoch 7 / 10 ========\n",
            "Training...\n",
            "  Batch   500  of  2,026.    Elapsed: 0:01:57.\n",
            "  Batch 1,000  of  2,026.    Elapsed: 0:03:54.\n",
            "  Batch 1,500  of  2,026.    Elapsed: 0:05:51.\n",
            "  Batch 2,000  of  2,026.    Elapsed: 0:07:48.\n",
            "\n",
            "  Average training loss: 0.2789\n",
            "  Training epcoh took: 0:07:54\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.71235\n",
            "  Validation took: 0:00:15\n",
            "\n",
            "======== Epoch 8 / 10 ========\n",
            "Training...\n",
            "  Batch   500  of  2,026.    Elapsed: 0:01:58.\n",
            "  Batch 1,000  of  2,026.    Elapsed: 0:03:55.\n",
            "  Batch 1,500  of  2,026.    Elapsed: 0:05:52.\n",
            "  Batch 2,000  of  2,026.    Elapsed: 0:07:49.\n",
            "\n",
            "  Average training loss: 0.2651\n",
            "  Training epcoh took: 0:07:55\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.70649\n",
            "  Validation took: 0:00:15\n",
            "\n",
            "======== Epoch 9 / 10 ========\n",
            "Training...\n",
            "  Batch   500  of  2,026.    Elapsed: 0:01:57.\n",
            "  Batch 1,000  of  2,026.    Elapsed: 0:03:54.\n",
            "  Batch 1,500  of  2,026.    Elapsed: 0:05:51.\n",
            "  Batch 2,000  of  2,026.    Elapsed: 0:07:47.\n",
            "\n",
            "  Average training loss: 0.2560\n",
            "  Training epcoh took: 0:07:53\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.71127\n",
            "  Validation took: 0:00:15\n",
            "\n",
            "======== Epoch 10 / 10 ========\n",
            "Training...\n",
            "  Batch   500  of  2,026.    Elapsed: 0:01:57.\n",
            "  Batch 1,000  of  2,026.    Elapsed: 0:03:55.\n",
            "  Batch 1,500  of  2,026.    Elapsed: 0:05:53.\n",
            "  Batch 2,000  of  2,026.    Elapsed: 0:07:50.\n",
            "\n",
            "  Average training loss: 0.2481\n",
            "  Training epcoh took: 0:07:56\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.71463\n",
            "  Validation took: 0:00:15\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0n1rmapDiDb"
      },
      "source": [
        "#Test Set 평가\r\n",
        "Spell check (test_data)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "duUvdU53AHr9",
        "outputId": "15438d03-3b30-44be-902d-37f8764132ed"
      },
      "source": [
        "test_data = pd.read_csv('en_data.csv', encoding = 'utf-8')\r\n",
        "test_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>i_dialog</th>\n",
              "      <th>i_utterance</th>\n",
              "      <th>speaker</th>\n",
              "      <th>utterance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Phoebe</td>\n",
              "      <td>Alright, whadyou do with him?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Monica</td>\n",
              "      <td>Oh! You're awake!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>Joey</td>\n",
              "      <td>Then you gotta come clean with Ma! This is not...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Mr. Tribbiani</td>\n",
              "      <td>Yeah, but this is</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>Joey</td>\n",
              "      <td>I don't wanna hear it! Now go to my room!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ...                                          utterance\n",
              "0   0  ...                      Alright, whadyou do with him?\n",
              "1   1  ...                                  Oh! You're awake!\n",
              "2   2  ...  Then you gotta come clean with Ma! This is not...\n",
              "3   3  ...                                  Yeah, but this is\n",
              "4   4  ...          I don't wanna hear it! Now go to my room!\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157,
          "referenced_widgets": [
            "5b96fe839ba540c680e5dbd9fec649e5",
            "fc41e7486eb0496a8ef4d5b6326f8dca",
            "5613e50d00f64fd08b9bc91f564a2633",
            "6d8a89285c584bfd8aa32e1491676551",
            "f81917b3f5a040579d17f712e776f4cd",
            "2b05d1d3409b4616af1352475228a69e",
            "04d29e8655dd4d30bcaf24c55b1e173d",
            "c70b713583e14f87a5edd4b6b1808d3f"
          ]
        },
        "id": "TSS1XGLeFu-G",
        "outputId": "6c8baa59-cc05-4a35-df8e-cfccda3c1b1c"
      },
      "source": [
        "#제출용 맞춤법검사\r\n",
        "for i in tqdm(range(len(test_data))):\r\n",
        "  try:\r\n",
        "    test_data['utterance'][i] = tool.correct(test_data['utterance'][i])\r\n",
        "  except:\r\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5b96fe839ba540c680e5dbd9fec649e5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1623.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y861jxQyHDyH"
      },
      "source": [
        "#데이터인풋\r\n",
        "test_data_inputs, test_data_masks = getInputsFromTest(test_data) #제출용"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wH85FEIVkbOa"
      },
      "source": [
        "#제출용(test_data)\r\n",
        "test_data_index = getIndex(test_data)\r\n",
        "test_data_inputs = torch.tensor(test_data_inputs)\r\n",
        "test_data_masks = torch.tensor(test_data_masks)\r\n",
        "\r\n",
        "test_data_data = TensorDataset(test_data_index, test_data_inputs, test_data_masks)\r\n",
        "test_data_sampler = RandomSampler(test_data_data)\r\n",
        "test_data_dataloader = DataLoader(test_data_data, sampler=test_data_sampler, batch_size=1) #batch=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyd_9TE3PSXR",
        "outputId": "42301047-6e1c-459c-f6fd-6107aae07fc8"
      },
      "source": [
        "#제출용 LABELING\n",
        "test_result = test_data.copy(deep = True)\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "labels = new_train['emotion'].values\n",
        "encoder.fit(labels)\n",
        "labels = encoder.transform(labels)\n",
        "\n",
        "test_result['predicted'] = 'default'\n",
        "\n",
        "for step, batch in enumerate(test_data_dataloader): #제출용: test_data_dataloader\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_index, b_input_ids, b_input_mask = batch\n",
        "    \n",
        "    with torch.no_grad():     \n",
        "        outputs = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask)\n",
        "    \n",
        "    logits = outputs[0]\n",
        "\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    idx = b_index.item()\n",
        "    test_result['predicted'][idx] = encoder.classes_[np.argmax(logits)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "Z34f7Gt_QO9E",
        "outputId": "87211013-bf9e-4797-d192-7f1001f2cda8"
      },
      "source": [
        "test_result[test_result['predicted']=='joy']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>i_dialog</th>\n",
              "      <th>i_utterance</th>\n",
              "      <th>speaker</th>\n",
              "      <th>utterance</th>\n",
              "      <th>predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>Chandler</td>\n",
              "      <td>If</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>24</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>Chandler</td>\n",
              "      <td>One more score to go! You can do it!</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>29</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>Ross</td>\n",
              "      <td>Phoebe!!</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>43</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>Ross</td>\n",
              "      <td>Yeah, you got it right? You got it right? You ...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>57</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>Rachel</td>\n",
              "      <td>Yeah!</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1587</th>\n",
              "      <td>1587</td>\n",
              "      <td>149</td>\n",
              "      <td>1</td>\n",
              "      <td>Joey</td>\n",
              "      <td>Hey!</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1591</th>\n",
              "      <td>1591</td>\n",
              "      <td>149</td>\n",
              "      <td>5</td>\n",
              "      <td>Joey</td>\n",
              "      <td>Nice!</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1604</th>\n",
              "      <td>1604</td>\n",
              "      <td>150</td>\n",
              "      <td>0</td>\n",
              "      <td>Phoebe</td>\n",
              "      <td>Hey!</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1607</th>\n",
              "      <td>1607</td>\n",
              "      <td>150</td>\n",
              "      <td>3</td>\n",
              "      <td>Monica</td>\n",
              "      <td>Oh-ho, look what I got Julio.</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1619</th>\n",
              "      <td>1619</td>\n",
              "      <td>150</td>\n",
              "      <td>15</td>\n",
              "      <td>Lauren</td>\n",
              "      <td>Hi, Kate!</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>230 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ...  predicted\n",
              "11      11  ...        joy\n",
              "24      24  ...        joy\n",
              "29      29  ...        joy\n",
              "43      43  ...        joy\n",
              "57      57  ...        joy\n",
              "...    ...  ...        ...\n",
              "1587  1587  ...        joy\n",
              "1591  1591  ...        joy\n",
              "1604  1604  ...        joy\n",
              "1607  1607  ...        joy\n",
              "1619  1619  ...        joy\n",
              "\n",
              "[230 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "0WXbum3JrVP-",
        "outputId": "8a5dfc88-bd0e-4bc7-e400-a427ba425216"
      },
      "source": [
        "test_result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>i_dialog</th>\n",
              "      <th>i_utterance</th>\n",
              "      <th>speaker</th>\n",
              "      <th>utterance</th>\n",
              "      <th>predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Phoebe</td>\n",
              "      <td>Alright, shadow do with him?</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Monica</td>\n",
              "      <td>Oh! You're awake!</td>\n",
              "      <td>surprise</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>Joey</td>\n",
              "      <td>Then you have to come clean with Ma! This is n...</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Mr. Tribbiani</td>\n",
              "      <td>Yeah, but this is</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>Joey</td>\n",
              "      <td>I don't want to hear it! Now go to my room!</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1618</th>\n",
              "      <td>1618</td>\n",
              "      <td>150</td>\n",
              "      <td>14</td>\n",
              "      <td>Joey</td>\n",
              "      <td>New.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1619</th>\n",
              "      <td>1619</td>\n",
              "      <td>150</td>\n",
              "      <td>15</td>\n",
              "      <td>Lauren</td>\n",
              "      <td>Hi, Kate!</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1620</th>\n",
              "      <td>1620</td>\n",
              "      <td>150</td>\n",
              "      <td>16</td>\n",
              "      <td>Kate</td>\n",
              "      <td>Hi, Lauren.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1621</th>\n",
              "      <td>1621</td>\n",
              "      <td>150</td>\n",
              "      <td>17</td>\n",
              "      <td>Joey</td>\n",
              "      <td>Hi, Lauren.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1622</th>\n",
              "      <td>1622</td>\n",
              "      <td>150</td>\n",
              "      <td>18</td>\n",
              "      <td>Lauren</td>\n",
              "      <td>Hi, pig!</td>\n",
              "      <td>non-neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1623 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ...    predicted\n",
              "0        0  ...      neutral\n",
              "1        1  ...     surprise\n",
              "2        2  ...        anger\n",
              "3        3  ...      neutral\n",
              "4        4  ...        anger\n",
              "...    ...  ...          ...\n",
              "1618  1618  ...      neutral\n",
              "1619  1619  ...          joy\n",
              "1620  1620  ...      neutral\n",
              "1621  1621  ...      neutral\n",
              "1622  1622  ...  non-neutral\n",
              "\n",
              "[1623 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SppWLWuyGWLh",
        "outputId": "5d2c6f72-60c0-4853-fcb6-bbfd51dee658"
      },
      "source": [
        "print(test_result['predicted'].value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "neutral        675\n",
            "non-neutral    331\n",
            "surprise       240\n",
            "joy            236\n",
            "anger           52\n",
            "sadness         47\n",
            "fear            23\n",
            "disgust         19\n",
            "Name: predicted, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "hSF-AK4URDAr",
        "outputId": "98cc67aa-dfeb-4cb3-f6e7-a4b40c4ea25f"
      },
      "source": [
        "test_result = test_result.drop(columns = ['i_dialog','i_utterance','speaker','utterance'])\r\n",
        "test_csv = test_result.to_csv('eng_result(1223).csv',encoding='utf-8', index=False)\r\n",
        "#다운로드\r\n",
        "files.download('eng_result(1223).csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_29daa0e8-89ce-4739-b4d0-3b1ace0bc487\", \"eng_result(1223).csv\", 20449)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2y-w0GsCKue"
      },
      "source": [
        "Spell Checker : https://pypi.org/project/language-tool-python/\r\n",
        "\r\n",
        "전체적인 모델링 코드 및 학습내용 참고 : \r\n",
        "\r\n",
        "1) https://mccormickml.com/2019/07/22/BERT-fine-tuning/\r\n",
        "\r\n",
        "2) https://colab.research.google.com/drive/1tIf0Ugdqg4qT7gcxia3tL7und64Rv1dP"
      ]
    }
  ]
}